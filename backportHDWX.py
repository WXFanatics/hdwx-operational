#!/usr/bin/env python3
# Backwards compatibility script to port python HDWX products to GEMPAK HDWX viewer
# Created 2 Feburary 2022 by Sam Gardner <stgardner4@tamu.edu>

import sys
import json
from os import path, listdir
from shutil import rmtree, copyfile
from pathlib import Path
import imageio
from atomicwrites import atomic_write

def generatePlaceholderImage():
    from matplotlib import pyplot as plt
    from cartopy import crs as ccrs
    from cartopy import feature as cfeat
    from matplotlib import image as mpimage
    fig = plt.figure()
    ax = plt.axes(projection=ccrs.epsg(3857))
    ax.set_extent([-130, -60, 20, 50], crs=ccrs.PlateCarree())
    ax.add_feature(cfeat.STATES.with_scale("50m"), linewidth=0.5)
    ax.add_feature(cfeat.COASTLINE.with_scale("50m"), linewidth=0.5)
    ax.text(-98.35, 39.5, "Product generation in progress.\nPlease stand by...", horizontalalignment="center", verticalalignment="center", fontsize=36, transform=ccrs.PlateCarree())
    # ax.set_position([ax.get_position().x0, .12, ax.get_position().width, ax.get_position().height])
    if path.exists(path.join(sys.argv[1], "assets", "atmoLogo.png")):
        lax = fig.add_axes([(.99-(ax.get_position().width/3)),0,(ax.get_position().width/3),.1])
        lax.set_aspect(2821/11071)
        lax.axis("off")
        plt.setp(lax.spines.values(), visible=False)
        atmoLogo = mpimage.imread(path.join(sys.argv[1], "assets", "atmoLogo.png"))
        lax.imshow(atmoLogo)
    px = 1/plt.rcParams["figure.dpi"]
    fig.set_size_inches(1920*px, 1080*px)
    fig.savefig(path.join("operational-metadata", "placeholder.png"))
    with imageio.get_writer(path.join("operational-metadata", "placeholder.gif"), mode="I") as writer:
        imageToConvert = imageio.imread(path.join("operational-metadata", "placeholder.png"))
        writer.append_data(imageToConvert)


if __name__ == "__main__":
    # Get path to hdwx root
    basePath = path.abspath(path.dirname(__file__))
    # Get requested submodule path from command-line argument
    submodulePath = sys.argv[1].replace("/", "")
    # Get the requested metadata dir, ./<submodule>/output/metadata/
    metadataDir = path.join(basePath, submodulePath, "output", "metadata")
    # List all of the registered products generated by this submodule
    if path.exists(metadataDir):
        generatedProductIDs = [jsonFileName.replace(".json", "") for jsonFileName in sorted(listdir(metadataDir)) if ".json" in jsonFileName]
    else:
        exit()
    # Now we iterate over all of the products generated by this submodule
    for productID in generatedProductIDs:
        # Get all available productRun json files
        productRunsDirPath = path.join(metadataDir, "products", productID)
        productRunsJsonPaths = [path.join(productRunsDirPath, runJsonFileName) for runJsonFileName in sorted(listdir(productRunsDirPath))]
        # If there are any runs available...
        if len(productRunsJsonPaths) > 0:    
            # Create empty list as container for the paths to the images that will go in the "backport" directory
            framesToCopy = list()
            framesFromProduct = list()
            # Load product metadata
            productJsonPath = path.join(metadataDir, productID+".json")
            if path.exists(productJsonPath):
                with open(productJsonPath, "r") as jsonRead:
                    productMetadata = json.load(jsonRead)
                # If we're not dealing with png images, none of this will work
                if productMetadata["fileExtension"] == "png":
                    # GIS products dont need to be made compatibile with the non-GIS product viewer
                    if productMetadata["isGIS"] == False:
                        # Create a temporary dir to hold the converted images
                        tempDir = path.join(basePath, "operational-metadata", productID+"-latest")
                        # Check to see if this directory already exists
                        if path.exists(tempDir):
                            # if it does, check to see if there's metadata from the last backport pass that can speed things up for us later...
                            if path.exists(path.join(tempDir, "info.json")):
                                # Read in this data to a dict
                                with open(path.join(tempDir, "info.json"), "r") as jsonRead:
                                    lastPassSrcAndDest = json.load(jsonRead)
                            # now delete and re-create the temp directory to empty it
                            rmtree(tempDir)
                        Path(tempDir).mkdir(parents=True, exist_ok=True)
                        # get product path
                        productPath = productMetadata["productPath"]
                        # Check if the product wants to have a single run loaded or backfill across multiple runs
                        if productMetadata["displayFrames"] <= 0:
                            # If the displayFrames is 0 (or less... although it shouldn't ever be... unless I think of some creative way to use that in the future)
                            # then we want entire the latest run, and only frames from the latest run
                            latestRunPath = productRunsJsonPaths[-1]
                            # Load metadata from latest run
                            with open(latestRunPath, "r") as jsonRead:
                                latestRunMetadata = json.load(jsonRead)
                            # get suffix for the latest run
                            runPathExtension = latestRunMetadata["pathExtension"]
                            # Add all available frames to the list of frames to copy
                            [framesToCopy.append(path.join(path.dirname(metadataDir), productPath, runPathExtension, productFrame["filename"])) for productFrame in latestRunMetadata["productFrames"]]
                            # Copy this list to "framesFromProduct" for archival purposes
                            framesFromProduct = framesToCopy.copy()
                            # But since all the available frames may not necessarily fill all the requested frames, we need to do something with the excess...
                            if len(framesToCopy) < latestRunMetadata["totalFrameCount"]:
                                # Use a placeholder image for frames after completion but less than the expected number of frames in the run
                                shouldUsePlaceHolder = True
                                # If the aforementioned placeholder image doesn't exist yet, generated it now
                                if not path.exists(path.join(basePath, "operational-metadata", "placeholder.gif")):
                                    generatePlaceholderImage()
                                # Fill the remaining frames with the path to the placeholder image
                                [framesToCopy.append(path.join(basePath, "operational-metadata", "placeholder.gif")) for _ in range(len(framesToCopy), latestRunMetadata["totalFrameCount"])]
                        else:
                            # If display frames is not 0, then we want to display that exact number of frames. If the latest run contains less than this value,
                            # then we want to backfill from previous runs.
                            # This is of course a "you just indexed out of bounds on that array" error waiting to happen, so careful tracking is needed
                            runsBack = 0
                            idxToApnd = 0
                            while len(framesToCopy) < productMetadata["displayFrames"]:
                                idxToApnd = idxToApnd - 1
                                if idxToApnd < 0:
                                    # We're going back one run
                                    runsBack = runsBack + 1
                                    # Check to see that we actually have another run to read in
                                    if (len(productRunsJsonPaths) - runsBack) >= 0:
                                        # Read in the run data from that index
                                        requestedRunPath = productRunsJsonPaths[-runsBack]
                                        with open(requestedRunPath, "r") as jsonRead:
                                            runMetadata = json.load(jsonRead)
                                        # We're about to start adding frames in reverse order, from the last frame to the first.
                                        # We need to know what index to start at (last), which is the length minus 1
                                        idxToApnd = len(runMetadata["productFrames"]) - 1
                                        # Update runPathExtension
                                        runPathExtension = runMetadata["pathExtension"]
                                    else:
                                        break
                                framesToCopy.append(path.join(path.dirname(metadataDir), productPath, runPathExtension, runMetadata["productFrames"][idxToApnd]["filename"]))
                            # Since we've just built this whole list backwards...
                            framesToCopy.reverse()
                            # Copy this list to "framesFromProduct" for archival purposes
                            framesFromProduct = framesToCopy.copy()
                            # If there aren't enough frames to fill the display frames, then repeat the list as many times as possible.
                            # This isn't perfect, as if you have 10 frames available, and "displayFrames" is 15, you'll get one and a half loops,
                            # but the alternative is just leaving the user on a blank screen which is not good UX
                            a = 0
                            while len(framesToCopy) < productMetadata["displayFrames"]:
                                framesToCopy.append(path.join(tempDir, "frame"+str(a)+".gif"))
                                a = a + 1
                        # Create a dicts to track image sources to destinations
                        thisPassSrcAndDest = dict()
                        lastPassSrcAndDest = dict()
                        # Get path to target directory
                        targetPath = path.join(path.dirname(metadataDir), productPath, "latest")
                        # Loop through the list of the source images
                        for i in range(0, len(framesToCopy)):
                            # Get the source and target file paths
                            sourceFile = framesToCopy[i]
                            targetFileEventually = path.join(targetPath, "frame"+str(i)+".gif")
                            targetFileNow = path.join(tempDir, "frame"+str(i)+".gif")
                            # if the source was already converted to a GIF on the last pass, then we can just copy that file instead of 
                            # re-converting
                            if sourceFile in lastPassSrcAndDest.keys():
                                sourceFile = lastPassSrcAndDest[sourceFile]
                            # Make sure this file path exists...
                            if path.exists(sourceFile):
                                # if the source is already a gif, all we need to do is copy it
                                if ".gif" in sourceFile:
                                    copyfile(sourceFile, targetFileNow)
                                # Otherwise, we have to convert the image to a GIF first, then write out
                                else:
                                    with imageio.get_writer(targetFileNow, mode="I") as writer:
                                        imageToConvert = imageio.imread(sourceFile)
                                        writer.append_data(imageToConvert)
                                # If the image we just wrote is in the "framesFromProduct" array, then we need to store what we converted it to,
                                # in case the original gets deleted by cleanup. This will also speed up the next pass as we can just copy the GIF
                                # next time instead of re-converting the png
                                if i < len(framesFromProduct):
                                    thisPassSrcAndDest[sourceFile] = targetFileEventually
                        # Generate a thumbnail from the first image
                        if path.exists(path.join(tempDir, "frame0.gif")):
                            copyfile(path.join(tempDir, "frame0.gif"), path.join(tempDir , "thumb.gif"))
                        # Now, delete the target directory and re-create it (to empty it)
                        if path.exists(targetPath):
                            rmtree(targetPath)
                        Path(targetPath).mkdir(parents=True, exist_ok=True)
                        # Copy the contents of the temporary directory to the target directory
                        [copyfile(path.join(tempDir, filename), path.join(targetPath, filename)) for filename in sorted(listdir(tempDir))]
                        # Write the metadata for the next pass to the temp dir
                        with atomic_write(path.join(tempDir, "info.json"), overwrite=True) as jsonWrite:
                            json.dump(thisPassSrcAndDest, jsonWrite, indent=4)